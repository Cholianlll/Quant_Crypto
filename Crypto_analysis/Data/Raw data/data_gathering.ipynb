{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 1:  Market quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hmac\n",
    "import time\n",
    "import hashlib\n",
    "import requests\n",
    "from urllib.parse import urljoin, urlencode\n",
    "\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for future market\n",
    "\n",
    "# Future\n",
    "# BASE_URL = 'https://fapi.binance.com' \n",
    "\n",
    "# Spot margin Saving Mining\n",
    "BASE_URL = 'https://api.binance.com'\n",
    "\n",
    "\n",
    "''' ======  begin of functions, you don't need to touch ====== '''\n",
    "def hashing(query_string):\n",
    "    return hmac.new(SECRET.encode('utf-8'), query_string.encode('utf-8'), hashlib.sha256).hexdigest()\n",
    "\n",
    "def get_timestamp():\n",
    "    return int(time.time() * 1000)\n",
    "\n",
    "\n",
    "def dispatch_request(http_method):\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'Content-Type': 'application/json;charset=utf-8',\n",
    "        'X-MBX-APIKEY': KEY\n",
    "    })\n",
    "    return {\n",
    "        'GET': session.get,\n",
    "        'DELETE': session.delete,\n",
    "        'PUT': session.put,\n",
    "        'POST': session.post,\n",
    "    }.get(http_method, 'GET')\n",
    "\n",
    "# used for sending request requires the signature\n",
    "def send_signed_request(http_method, url_path, payload={}):\n",
    "    query_string = urlencode(payload, True)\n",
    "    \n",
    "    if query_string:\n",
    "        query_string = \"{}&timestamp={}\".format(query_string, get_timestamp())\n",
    "    else:\n",
    "        query_string = 'timestamp={}'.format(get_timestamp())\n",
    "\n",
    "    url = BASE_URL + url_path + '?' + query_string + '&signature=' + hashing(query_string)\n",
    "    # print(\"{} {}\".format(http_method, url))\n",
    "    params = {'url': url, 'params': {}}\n",
    "    response = dispatch_request(http_method)(**params)\n",
    "    return response.json()\n",
    "\n",
    "# used for sending public data request\n",
    "def send_public_request(url_path, payload={}):\n",
    "    query_string = urlencode(payload, True)\n",
    "    url = BASE_URL + url_path\n",
    "    if query_string:\n",
    "        url = url + '?' + query_string\n",
    "    # print(\"{}\".format(url))\n",
    "    # response = dispatch_request('GET')(url=url)\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "''' ======  end of functions ====== '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exchange info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'BTCUSDT'\n",
    "quantity = 0.003\n",
    "\n",
    "# params = {\n",
    "#     'symbol': symbol,\n",
    "#     'side': 'SELL',\n",
    "#     'type': 'MARKET',\n",
    "#     'quantity': quantity,\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    \n",
    "}\n",
    "\n",
    "url_path = '/api/v3/exchangeInfo'\n",
    "\n",
    "response = send_public_request(url_path, params)\n",
    "\n",
    "# json_normalize(response['symbols'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kline/Candlestick Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def kline_data(stime, etime, symbol = 'BTCUSDT', interval = '1d'):\n",
    "    \n",
    "    stimestamp = int(datetime.datetime.strptime(stime, \"%Y-%m-%d\").timestamp()*1000)\n",
    "    etimestamp = int(datetime.datetime.strptime(etime, \"%Y-%m-%d\").timestamp()*1000)\n",
    "\n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'startTime': stimestamp,\n",
    "        'endTime': etimestamp,\n",
    "        'limit': 1000,\n",
    "    }\n",
    "\n",
    "    url_path = '/api/v3/klines'\n",
    "\n",
    "    response = send_public_request(url_path, params)\n",
    "\n",
    "    data = pd.DataFrame(response)\n",
    "\n",
    "    col = ['Open_time','Open','High','Low','Close','Volume','Close_time','Quote_asset_volume','Number_of_trades',\n",
    "        'Taker_buy_volume','Taker_buy_quote_asset_volume','Ignore']\n",
    "\n",
    "    data.columns = col\n",
    "    #       transfer the timestamp into time\n",
    "    data['Open_time'] = pd.to_datetime(data['Open_time'],unit='ms',utc=True)\n",
    "    data['Close_time'] = pd.to_datetime(data['Close_time'],unit='ms',utc=True)\n",
    "    \n",
    "    data.iloc[:,[1,2,3,4,5,7,9,10]] = data.iloc[:,[1,2,3,4,5,7,9,10]].astype(float)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = \"2018-12-31\"\n",
    "etime = \"2020-01-01\"\n",
    "symbol = 'ETHUSDT'\n",
    "interval = '1d'\n",
    "\n",
    "data1 = kline_data(stime,etime,symbol,interval)\n",
    "\n",
    "stime = \"2020-01-01\"\n",
    "etime = \"2022-05-01\"\n",
    "symbol = 'BTCUSDT'\n",
    "interval = '1d'\n",
    "\n",
    "data2 = kline_data(stime,etime,symbol,interval)\n",
    "\n",
    "data = pd.concat([data1,data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['daily_return'] = data.Close/data.Open - 1\n",
    "data['price_vol'] = (data.High-data.Low)/data.Open\n",
    "data['log_price'] = np.log(data.Close)\n",
    "data['volumn_pct'] = data.Volume.pct_change()\n",
    "\n",
    "data.Open_time = data.Open_time.dt.strftime('%Y-%m-%d')\n",
    "data.Close_time = data.Close_time.dt.strftime('%Y-%m-%d')\n",
    "data = data.drop(['Ignore','Open_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns ={'Close_time':'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Close_shift_1'] = data.Close.shift(1)\n",
    "data['Close_shift_2'] = data.Close.shift(2)\n",
    "data['Close_shift_3'] = data.Close.shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('MarketqutoesData/BTCUSDT_daily.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TechIndicatorsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import talib as ta\n",
    "import numpy as np\n",
    "from FinTechTools import multiple_ta\n",
    "\n",
    "data = pd.read_csv('MarketqutoesData/BTCUSDT_daily.csv',index_col= 0)\n",
    "\n",
    "data.date = pd.to_datetime(data.date)\n",
    "ind_list,name_list = multiple_ta(data)\n",
    "\n",
    "data_ind = pd.DataFrame()\n",
    "for i in range(len(ind_list)):\n",
    "    data_ind = pd.concat([data_ind,pd.DataFrame(ind_list[i])],axis=1)\n",
    "    \n",
    "data_ind.columns = name_list\n",
    "data_ind['date'] = data.date\n",
    "\n",
    "# drop columns with inf values\n",
    "inf_col = lambda x: sum(x == np.inf)>1 \n",
    "# print(data_ind.columns[data.apply(inf_col)])\n",
    "data_ind = data_ind.drop(data_ind.columns[data_ind.apply(inf_col)],axis = 1)\n",
    "\n",
    "# Save data\n",
    "data_ind.to_csv('TechIndicatorsData/All_indicator.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blockchain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "filenames = next(walk(f\"BlockchainData/Raw data/\"), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "data = pd.read_csv(f'BlockchainData/Raw data/{filenames[0]}')\n",
    "data.Timestamp = pd.to_datetime(data.Timestamp)\n",
    "data.Timestamp = data.Timestamp.dt.strftime('%Y-%m-%d')\n",
    "data = data.groupby('Timestamp').mean().reset_index(drop=False)\n",
    "\n",
    "for i in range(1,len(filenames)):\n",
    "    f = filenames[i]\n",
    "    d = pd.read_csv(f'BlockchainData/Raw data/{f}')\n",
    "    d.Timestamp = pd.to_datetime(d.Timestamp)\n",
    "    d.Timestamp = d.Timestamp.dt.strftime('%Y-%m-%d')\n",
    "    d = d.groupby('Timestamp').mean().reset_index(drop=False)\n",
    "    data = data.merge(d,on = 'Timestamp', how = 'outer')\n",
    "    \n",
    "data = data.sort_values(by = 'Timestamp')\n",
    "data = data.rename(columns ={'Timestamp':'date'})\n",
    "\n",
    "data.to_csv('BlockchainData/Blockchaindata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobalCurrencyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('GlobalCurrencyData/Raw data/WS_XRU_D_csv_row.csv')\n",
    "\n",
    "col = data.iloc[1,:]\n",
    "col = col.str.split(':').str[0]\n",
    "\n",
    "data = data.iloc[8:,:]\n",
    "data.columns = col\n",
    "\n",
    "major_country = ['Currency','CNY','JPY','EUR','GBP','INR','BRL','CAD','KRW']\n",
    "\n",
    "data = data[major_country].loc[:,~data[major_country].columns.duplicated()]\n",
    "\n",
    "data = data.rename(columns ={'Currency':'date'})\n",
    "\n",
    "data.to_csv('GlobalCurrencyData/GlobalCurrencydata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "# read data\n",
    "data_blockchain = pd.read_csv('BlockchainData/Blockchaindata.csv', index_col =0)\n",
    "data_globalcurrency = pd.read_csv('GlobalCurrencyData/GlobalCurrencydata.csv', index_col =0)\n",
    "data_marketquotes = pd.read_csv('MarketqutoesData/BTCUSDT_daily.csv', index_col =0)\n",
    "data_techindicators = pd.read_csv('TechIndicatorsData/All_indicator.csv', index_col =0)\n",
    "\n",
    "d_ls = [data_blockchain,data_globalcurrency,data_marketquotes,data_techindicators]\n",
    "data = reduce(lambda  left,right: pd.merge(left,right,on=['date'],\n",
    "                                            how='outer'), d_ls).sort_values(by = \"date\")\n",
    "## missing values of response variables\n",
    "data['y_prediction'] = data.Close.shift(-1)\n",
    "data['y_classification'] = (data.Close>data.Open).apply(lambda x: 'up' if x else 'down').shift(-1)\n",
    "data = data.dropna(subset = ['Close','utxo-count','y_prediction','y_classification'])\n",
    "\n",
    "data.drop('y_classification',axis = 1).to_csv('../Clean data/Prediction/ori_data_prediction.csv')\n",
    "data.drop('y_prediction',axis = 1).to_csv('../Clean data/Classification/ori_data_classification.csv')\n",
    "\n",
    "# drop columns with high proportion of missing values\n",
    "ms_col = data.isna().sum()[data.isna().sum()>data.shape[0]*0.5].index\n",
    "data = data.drop(ms_col,axis=1)\n",
    "\n",
    "data = data.set_index('date',drop=True)\n",
    "data = data.interpolate().dropna()\n",
    "\n",
    "# y transformation\n",
    "data.y_prediction = np.log(data.y_prediction)\n",
    "data.y_classification = data.y_classification\n",
    "\n",
    "# train test split\n",
    "train_df = data[(pd.to_datetime(data.index).year < 2022)].reset_index(drop = True)\n",
    "test_df = data[(pd.to_datetime(data.index).year >= 2022)].reset_index(drop = True)\n",
    "X_train = train_df.iloc[:,:-2]\n",
    "y_train = train_df.iloc[:,-2:]\n",
    "\n",
    "X_test = test_df.iloc[:,:-2]\n",
    "y_test = test_df.iloc[:,-2:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train.iloc[:,:] = scaler.fit_transform(X_train)\n",
    "X_test.iloc[:,:] = scaler.transform(X_test)\n",
    "\n",
    "train_clean = pd.concat([X_train, y_train],axis=1)\n",
    "test_clean = pd.concat([X_test, y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.drop('y_classification',axis = 1).to_csv('../Clean data/Prediction/Clean_data_train.csv')\n",
    "test_clean.drop('y_classification',axis = 1).to_csv('../Clean data/Prediction/Clean_data_test.csv')\n",
    "train_clean.drop('y_prediction',axis = 1).to_csv('../Clean data/Classification/Clean_data_train.csv')\n",
    "test_clean.drop('y_prediction',axis = 1).to_csv('../Clean data/Classification/Clean_data_test.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a33b775cd6344257653a6d40ab6b5f2969c84566975f51b8eb6ff1553bceff8c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
